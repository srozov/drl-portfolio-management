{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitation Learning for Portfolio Management using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps to try:**\n",
    "1. We first try to overfit a 3 stocks toy case using 3 years of training data.\n",
    "2. Try to generalize to other years of the same stock.\n",
    "3. Get some insigts on network topology and hyperparameter tuning.\n",
    "4. Increase the number of stocks. (Increase action space to more than 10.)\n",
    "\n",
    "**Possible improvement methods:**\n",
    "1. Use correlated action noise\n",
    "2. Use adaptive parameter noise\n",
    "\n",
    "**Figures to show:**\n",
    "1. Training: total rewards w.r.t episode\n",
    "2. How the model performs on training data\n",
    "3. How the model performs on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATABASE_NAME=timescaledb\n",
      "env: DATABASE_HOST=localhost\n",
      "env: DATABASE_PORT=5432\n",
      "env: DATABASE_USER=timescaledb\n",
      "env: DATABASE_PASSWORD=yourmomasofat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.data import read_stock_history, index_to_date, date_to_index\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for compatible with python 3\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env DATABASE_NAME=timescaledb\n",
    "%env DATABASE_HOST=localhost\n",
    "%env DATABASE_PORT=5432\n",
    "%env DATABASE_USER=timescaledb\n",
    "%env DATABASE_PASSWORD=yourmomasofat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# force tensorflow to use CPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "\n",
    "endpoint=\"postgresql://{}:{}@{}?port={}&dbname={}\".format(\n",
    "    os.environ['DATABASE_USER'],\n",
    "    os.environ['DATABASE_PASSWORD'],\n",
    "    os.environ['DATABASE_HOST'],\n",
    "    os.environ['DATABASE_PORT'],\n",
    "    os.environ['DATABASE_NAME'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dataset: (num_stocks, timestamp, 5) open, high, low, close, volume\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 16:30:09.596928: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 FMA\n",
      "2022-12-11 16:30:09.857014: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-11 16:30:09.903723: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-11 16:30:11.952111: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n",
      "2022-12-11 16:30:11.952198: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at sql_kernels.cc:178 : INVALID_ARGUMENT: OID of data type 114 is not supported\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "OID of data type 114 is not supported [Op:IO>SqlIterableInit]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 48\u001B[0m\n\u001B[1;32m      6\u001B[0m query_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124mSELECT\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124m    extract(epoch from time) AS time,\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124mLIMIT 2000\u001B[39m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     26\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124mSELECT\u001B[39m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124m    extract(epoch from time) AS time,\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124mLIMIT 2000\u001B[39m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 48\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtfio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIODataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_sql\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# print(dataset.element_spec)\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow_io/python/experimental/io_dataset_ops.py:238\u001B[0m, in \u001B[0;36mIODataset.from_sql\u001B[0;34m(cls, query, endpoint, spec)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_sql\u001B[39m(\u001B[38;5;28mcls\u001B[39m, query, endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;124;03m\"\"\"Creates an `GraphIODataset` from a postgresql server endpoint.\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;124;03m      A `IODataset`.\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 238\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msql_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSQLIODataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow_io/python/experimental/sql_dataset_ops.py:29\u001B[0m, in \u001B[0;36mSQLIODataset.__init__\u001B[0;34m(self, query, endpoint, spec, internal)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m internal\n\u001B[1;32m     28\u001B[0m endpoint \u001B[38;5;241m=\u001B[39m endpoint \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 29\u001B[0m resource, count, fields, dtypes \u001B[38;5;241m=\u001B[39m \u001B[43mcore_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio_sql_iterable_init\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     fields \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39munstack(fields)\n",
      "File \u001B[0;32m<string>:11000\u001B[0m, in \u001B[0;36mio_sql_iterable_init\u001B[0;34m(input, endpoint, container, shared_name, name)\u001B[0m\n",
      "File \u001B[0;32m<string>:11065\u001B[0m, in \u001B[0;36mio_sql_iterable_init_eager_fallback\u001B[0;34m(input, endpoint, container, shared_name, name, ctx)\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     57\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 58\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     61\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: OID of data type 114 is not supported [Op:IO>SqlIterableInit]"
     ]
    }
   ],
   "source": [
    "query_1 = \"SELECT extract(epoch from time) AS time, open FROM ohlc_candleseries WHERE symbol = 'LTC/USDT' LIMIT 2000;\"\n",
    "\n",
    "query_tmp = \"SELECT extract(epoch from time) AS time, open FROM ohlc_candleseries WHERE symbol = '{}' LIMIT {};\"\n",
    "\n",
    "\n",
    "query_2 = \"\"\"\n",
    "SELECT\n",
    "    extract(epoch from time) AS time,\n",
    "    array[\n",
    "            MAX(open) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "            MAX(high) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "            MAX(low) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "            MAX(close) FILTER (WHERE symbol = 'BTC/USDT')\n",
    "    ] AS btc,\n",
    "    array[\n",
    "            MAX(open) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(high) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(low) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(close) FILTER (WHERE symbol = 'LTC/USDT')\n",
    "    ] AS ltc\n",
    "\n",
    "FROM ohlc_candleseries\n",
    "GROUP BY extract(epoch from time)\n",
    "LIMIT 2000\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    extract(epoch from time) AS time,\n",
    "    json_build_array(\n",
    "                MAX(open) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "                MAX(high) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "                MAX(low) FILTER (WHERE symbol = 'BTC/USDT'),\n",
    "                MAX(close) FILTER (WHERE symbol = 'BTC/USDT')\n",
    "    ) AS btc,\n",
    "    json_build_array(\n",
    "            MAX(open) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(high) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(low) FILTER (WHERE symbol = 'LTC/USDT'),\n",
    "            MAX(close) FILTER (WHERE symbol = 'LTC/USDT')\n",
    "    ) AS ltc\n",
    "\n",
    "FROM ohlc_candleseries\n",
    "GROUP BY extract(epoch from time)\n",
    "LIMIT 2000\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dataset = tfio.experimental.IODataset.from_sql(\n",
    "    query=query,\n",
    "    endpoint=endpoint,\n",
    "    spec=(tf.int16, (tf.int16, tf.int16, tf.int16, tf.int16), (tf.int16, tf.int16, tf.int16, tf.int16))\n",
    ")\n",
    "\n",
    "# print(dataset.element_spec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 17:44:14.805806: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-11 17:44:15.166484: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n"
     ]
    }
   ],
   "source": [
    "_ = tfio.experimental.IODataset.from_sql(\n",
    "    query=query_tmp.format('BTC/USDT', 200),\n",
    "    endpoint=endpoint,\n",
    ").batch(50).shuffle(9).take(1).batch(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n 'l': TensorSpec(shape=(None,), dtype=tf.string, name=None)}"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices({\n",
    "    'x': [1, 2, 3, 4, 5, 6, 7, 8 , 9 ],\n",
    "    'l': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i' ]\n",
    "}).batch(6).take(1)\n",
    "\n",
    "ds.element_spec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'x': array([1, 2, 3, 4, 5, 6], dtype=int32),\n  'l': array([b'a', b'b', b'c', b'd', b'e', b'f'], dtype=object)}]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'x': array([1, 2, 3, 4, 5, 6], dtype=int32),\n  'l': array([b'a', b'b', b'c', b'd', b'e', b'f'], dtype=object)}]"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(tf.data.Dataset.zip(ds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 23:53:05.751327: W tensorflow/core/framework/dataset.cc:744] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5] | [50, 51, 52, 53, 54]\n",
      "[2, 3, 4, 5, 6] | [51, 52, 53, 54, 55]\n",
      "[3, 4, 5, 6, 7] | [52, 53, 54, 55, 56]\n",
      "[4, 5, 6, 7, 8] | [53, 54, 55, 56, 57]\n",
      "[5, 6, 7, 8, 9] | [54, 55, 56, 57, 58]\n",
      "[6, 7, 8, 9, 10] | [55, 56, 57, 58, 59]\n",
      "[7, 8, 9, 10, 11] | [56, 57, 58, 59, 60]\n",
      "[8, 9, 10, 11, 12] | [57, 58, 59, 60, 61]\n",
      "[9, 10, 11, 12, 13] | [58, 59, 60, 61, 62]\n",
      "[10, 11, 12, 13, 14] | [59, 60, 61, 62, 63]\n",
      "[11, 12, 13, 14, 15] | [60, 61, 62, 63, 64]\n",
      "[12, 13, 14, 15, 16] | [61, 62, 63, 64, 65]\n",
      "[13, 14, 15, 16, 17] | [62, 63, 64, 65, 66]\n",
      "[14, 15, 16, 17, 18] | [63, 64, 65, 66, 67]\n",
      "[15, 16, 17, 18, 19] | [64, 65, 66, 67, 68]\n",
      "[16, 17, 18, 19, 20] | [65, 66, 67, 68, 69]\n",
      "[17, 18, 19, 20, 21] | [66, 67, 68, 69, 70]\n",
      "[18, 19, 20, 21, 22] | [67, 68, 69, 70, 71]\n",
      "[19, 20, 21, 22, 23] | [68, 69, 70, 71, 72]\n",
      "[20, 21, 22, 23, 24] | [69, 70, 71, 72, 73]\n",
      "[21, 22, 23, 24, 25] | [70, 71, 72, 73, 74]\n",
      "[22, 23, 24, 25, 26] | [71, 72, 73, 74, 75]\n",
      "[23, 24, 25, 26, 27] | [72, 73, 74, 75, 76]\n",
      "[24, 25, 26, 27, 28] | [73, 74, 75, 76, 77]\n",
      "[25, 26, 27, 28, 29] | [74, 75, 76, 77, 78]\n",
      "[26, 27, 28, 29, 30] | [75, 76, 77, 78, 79]\n",
      "[27, 28, 29, 30, 31] | [76, 77, 78, 79, 80]\n",
      "[28, 29, 30, 31, 32] | [77, 78, 79, 80, 81]\n",
      "[29, 30, 31, 32, 33] | [78, 79, 80, 81, 82]\n",
      "[30, 31, 32, 33, 34] | [79, 80, 81, 82, 83]\n",
      "[31, 32, 33, 34, 35] | [80, 81, 82, 83, 84]\n",
      "[32, 33, 34, 35, 36] | [81, 82, 83, 84, 85]\n",
      "[33, 34, 35, 36, 37] | [82, 83, 84, 85, 86]\n",
      "[34, 35, 36, 37, 38] | [83, 84, 85, 86, 87]\n",
      "[35, 36, 37, 38, 39] | [84, 85, 86, 87, 88]\n",
      "[36, 37, 38, 39, 40] | [85, 86, 87, 88, 89]\n",
      "[37, 38, 39, 40, 41] | [86, 87, 88, 89, 90]\n",
      "[38, 39, 40, 41, 42] | [87, 88, 89, 90, 91]\n",
      "[39, 40, 41, 42, 43] | [88, 89, 90, 91, 92]\n",
      "[40, 41, 42, 43, 44] | [89, 90, 91, 92, 93]\n",
      "[41, 42, 43, 44, 45] | [90, 91, 92, 93, 94]\n",
      "[42, 43, 44, 45, 46] | [91, 92, 93, 94, 95]\n",
      "[43, 44, 45, 46, 47] | [92, 93, 94, 95, 96]\n",
      "[44, 45, 46, 47, 48] | [93, 94, 95, 96, 97]\n",
      "[45, 46, 47, 48, 49] | [94, 95, 96, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "a = tf.data.Dataset.range(1, 50)\n",
    "b = tf.data.Dataset.range(50, 150)\n",
    "ds = tf.data.Dataset.zip({'a': a, 'b': b})\n",
    "\n",
    "ds = ds.window(5, shift=1, stride=1, drop_remainder=True)\n",
    "\n",
    "for w in ds:\n",
    "    print(list(w['a'].as_numpy_iterator()), '|', list(w['b'].as_numpy_iterator()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :  1\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[1, 2, 3, 4, 5],\n",
      "       [2, 3, 4, 5, 6],\n",
      "       [3, 4, 5, 6, 7],\n",
      "       [4, 5, 6, 7, 8],\n",
      "       [5, 6, 7, 8, 9]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[50, 51, 52, 53, 54],\n",
      "       [51, 52, 53, 54, 55],\n",
      "       [52, 53, 54, 55, 56],\n",
      "       [53, 54, 55, 56, 57],\n",
      "       [54, 55, 56, 57, 58]])>}\n",
      "batch :  2\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[ 6,  7,  8,  9, 10],\n",
      "       [ 7,  8,  9, 10, 11],\n",
      "       [ 8,  9, 10, 11, 12],\n",
      "       [ 9, 10, 11, 12, 13],\n",
      "       [10, 11, 12, 13, 14]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[55, 56, 57, 58, 59],\n",
      "       [56, 57, 58, 59, 60],\n",
      "       [57, 58, 59, 60, 61],\n",
      "       [58, 59, 60, 61, 62],\n",
      "       [59, 60, 61, 62, 63]])>}\n",
      "batch :  3\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[11, 12, 13, 14, 15],\n",
      "       [12, 13, 14, 15, 16],\n",
      "       [13, 14, 15, 16, 17],\n",
      "       [14, 15, 16, 17, 18],\n",
      "       [15, 16, 17, 18, 19]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[60, 61, 62, 63, 64],\n",
      "       [61, 62, 63, 64, 65],\n",
      "       [62, 63, 64, 65, 66],\n",
      "       [63, 64, 65, 66, 67],\n",
      "       [64, 65, 66, 67, 68]])>}\n",
      "batch :  4\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[16, 17, 18, 19, 20],\n",
      "       [17, 18, 19, 20, 21],\n",
      "       [18, 19, 20, 21, 22],\n",
      "       [19, 20, 21, 22, 23],\n",
      "       [20, 21, 22, 23, 24]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[65, 66, 67, 68, 69],\n",
      "       [66, 67, 68, 69, 70],\n",
      "       [67, 68, 69, 70, 71],\n",
      "       [68, 69, 70, 71, 72],\n",
      "       [69, 70, 71, 72, 73]])>}\n",
      "batch :  5\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[21, 22, 23, 24, 25],\n",
      "       [22, 23, 24, 25, 26],\n",
      "       [23, 24, 25, 26, 27],\n",
      "       [24, 25, 26, 27, 28],\n",
      "       [25, 26, 27, 28, 29]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[70, 71, 72, 73, 74],\n",
      "       [71, 72, 73, 74, 75],\n",
      "       [72, 73, 74, 75, 76],\n",
      "       [73, 74, 75, 76, 77],\n",
      "       [74, 75, 76, 77, 78]])>}\n",
      "batch :  6\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[26, 27, 28, 29, 30],\n",
      "       [27, 28, 29, 30, 31],\n",
      "       [28, 29, 30, 31, 32],\n",
      "       [29, 30, 31, 32, 33],\n",
      "       [30, 31, 32, 33, 34]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[75, 76, 77, 78, 79],\n",
      "       [76, 77, 78, 79, 80],\n",
      "       [77, 78, 79, 80, 81],\n",
      "       [78, 79, 80, 81, 82],\n",
      "       [79, 80, 81, 82, 83]])>}\n",
      "batch :  7\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[31, 32, 33, 34, 35],\n",
      "       [32, 33, 34, 35, 36],\n",
      "       [33, 34, 35, 36, 37],\n",
      "       [34, 35, 36, 37, 38],\n",
      "       [35, 36, 37, 38, 39]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[80, 81, 82, 83, 84],\n",
      "       [81, 82, 83, 84, 85],\n",
      "       [82, 83, 84, 85, 86],\n",
      "       [83, 84, 85, 86, 87],\n",
      "       [84, 85, 86, 87, 88]])>}\n",
      "batch :  8\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[36, 37, 38, 39, 40],\n",
      "       [37, 38, 39, 40, 41],\n",
      "       [38, 39, 40, 41, 42],\n",
      "       [39, 40, 41, 42, 43],\n",
      "       [40, 41, 42, 43, 44]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[85, 86, 87, 88, 89],\n",
      "       [86, 87, 88, 89, 90],\n",
      "       [87, 88, 89, 90, 91],\n",
      "       [88, 89, 90, 91, 92],\n",
      "       [89, 90, 91, 92, 93]])>}\n",
      "batch :  9\n",
      "{'a': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[41, 42, 43, 44, 45],\n",
      "       [42, 43, 44, 45, 46],\n",
      "       [43, 44, 45, 46, 47],\n",
      "       [44, 45, 46, 47, 48],\n",
      "       [45, 46, 47, 48, 49]])>, 'b': <tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n",
      "array([[90, 91, 92, 93, 94],\n",
      "       [91, 92, 93, 94, 95],\n",
      "       [92, 93, 94, 95, 96],\n",
      "       [93, 94, 95, 96, 97],\n",
      "       [94, 95, 96, 97, 98]])>}\n"
     ]
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(1, 50)\n",
    "b = tf.data.Dataset.range(50, 150)\n",
    "ds = tf.data.Dataset.zip({'a': a, 'b': b})\n",
    "\n",
    "ds = ds.window(5, shift=1, stride=1, drop_remainder=True).flat_map(lambda x: tf.data.Dataset.zip({'a': x['a'], 'b': x['b']}).batch(5)).batch(5)\n",
    "b=0\n",
    "for w in ds:\n",
    "    # print(w)\n",
    "    b+=1\n",
    "    print('batch : ', b)\n",
    "    print(w)\n",
    "    # print(w['a'], '|',w['b'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "# Create a window of size 3, with a shift of 1 and a stride of 1\n",
    "ds = ds.window(3, shift=1, stride=1)\n",
    "\n",
    "# Iterate through the batches in the dataset\n",
    "for batch in ds:\n",
    "    # Iterate through the windows in the batch\n",
    "    for window in batch:\n",
    "      # Print the windowed dataset\n",
    "      print(window)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ZipDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[388], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# zipped = tf.data.Dataset.zip((a, b))\u001B[39;00m\n\u001B[1;32m      4\u001B[0m ds \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: a, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m: b})\n\u001B[0;32m----> 6\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# ds = ds.map()\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mlist\u001B[39m(ds\u001B[38;5;241m.\u001B[39mas_numpy_iterator())\n",
      "\u001B[0;31mTypeError\u001B[0m: 'ZipDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a = tf.data.Dataset.range(1, 16)\n",
    "b = tf.data.Dataset.range(16, 32)\n",
    "# zipped = tf.data.Dataset.zip((a, b))\n",
    "ds = tf.data.Dataset.zip({'a': a, 'b': b})\n",
    "\n",
    "ds = ds[0:7]\n",
    "# ds = ds.map()\n",
    "\n",
    "list(ds.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ub\n",
      "{'a': <tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 2, 3, 4, 5, 6, 7, 8])>, 'b': <tf.Tensor: shape=(8,), dtype=int64, numpy=array([16, 17, 18, 19, 20, 21, 22, 23])>}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'window'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[348], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mub\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(ub)\n\u001B[0;32m----> 8\u001B[0m windows_ub \u001B[38;5;241m=\u001B[39m \u001B[43mub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m(\u001B[38;5;241m3\u001B[39m, shift\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, drop_remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwindows_ub\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(windows_ub)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'window'"
     ]
    }
   ],
   "source": [
    "ds = ds.batch(8, drop_remainder=True)\n",
    "# list(batched_dataset.take(1).unbatch().as_numpy_iterator())\n",
    "# ds = ds.map(lambda b: b.batch(8))\n",
    "\n",
    "for ub in ds:\n",
    "    print('ub')\n",
    "    print(ub)\n",
    "    windows_ub = ub.window(3, shift=1, stride=1, drop_remainder=True)\n",
    "    print('windows_ub')\n",
    "    print(windows_ub)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=16>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=17>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=18>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=19>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=5>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=20>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=6>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=21>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=22>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=8>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=23>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=9>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=24>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=10>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=25>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=11>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=26>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=12>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=27>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=13>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=28>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=14>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=29>}\n",
      "{'a': <tf.Tensor: shape=(), dtype=int64, numpy=15>, 'b': <tf.Tensor: shape=(), dtype=int64, numpy=30>}\n"
     ]
    }
   ],
   "source": [
    "for ub in batched_dataset.unbatch():\n",
    "    print(ub)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int64) | tf.Tensor([16 17 18 19 20 21 22 23 24], shape=(9,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "batches = zipped.batch(9)\n",
    "for b in batches.take(1):\n",
    "    print(b['a'], '|', b['b'])\n",
    "    # print(list(w['a'].as_numpy_iterator()), ', ' ,list(w['b'].as_numpy_iterator()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] ,  [16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "windows = zipped.window(3, shift=1, stride=1)\n",
    "\n",
    "for w in windows.take(1):\n",
    "    print(list(w['a'].as_numpy_iterator()), ', ' ,list(w['b'].as_numpy_iterator()))\n",
    "    # print(tf.nest.map_structure(to_numpy, w))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[250], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m windows \u001B[38;5;241m=\u001B[39m zipped\u001B[38;5;241m.\u001B[39mwindow(\u001B[38;5;241m3\u001B[39m, shift\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mflat_map(\u001B[38;5;28;01mlambda\u001B[39;00m a ,b : tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip((a, b))\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m3\u001B[39m))\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m windows\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# print(w.numpy())\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mto_numpy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   \u001B[38;5;66;03m# print(w.as_numpy_iterator())\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    865\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m    866\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[0;32m--> 869\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[1;32m    870\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    865\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m    866\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[0;32m--> 869\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[1;32m    870\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "Cell \u001B[0;32mIn[124], line 3\u001B[0m, in \u001B[0;36mto_numpy\u001B[0;34m(ds)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_numpy\u001B[39m(ds):\n\u001B[0;32m----> 3\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_numpy_iterator\u001B[49m())\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:442\u001B[0m, in \u001B[0;36mTensor.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mravel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranspose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreshape\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclip\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    435\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtolist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[1;32m    436\u001B[0m   \u001B[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001B[39;00m\n\u001B[1;32m    437\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001B[39m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001B[39m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;124m    np_config.enable_numpy_behavior()\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n\u001B[0;32m--> 442\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "windows = zipped.window(3, shift=1, stride=1).flat_map(lambda a ,b : tf.data.Dataset.zip((a, b)).batch(3))\n",
    "for w in windows.take(2):\n",
    "    # print(w.numpy())\n",
    "    tf.nest.map_structure(to_numpy, w)\n",
    "  # print(w.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 16),\n (2, 17),\n (3, 18),\n (2, 17),\n (3, 18),\n (4, 19),\n (3, 18),\n (4, 19),\n (5, 20),\n (4, 19),\n (5, 20),\n (6, 21),\n (5, 20),\n (6, 21),\n (7, 22),\n (6, 21),\n (7, 22),\n (8, 23),\n (7, 22),\n (8, 23),\n (9, 24),\n (8, 23),\n (9, 24),\n (10, 25),\n (9, 24),\n (10, 25),\n (11, 26),\n (10, 25),\n (11, 26),\n (12, 27),\n (11, 26),\n (12, 27),\n (13, 28),\n (12, 27),\n (13, 28),\n (14, 29),\n (13, 28),\n (14, 29),\n (15, 30),\n (14, 29),\n (15, 30),\n (15, 30)]"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(windows.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride, drop_remainder=True)\n",
    "\n",
    "  def sub_to_batch(sub):\n",
    "\n",
    "    print('sub : ', sub)\n",
    "    print('type(sub) : ', type(sub))\n",
    "\n",
    "    return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "\n",
    "  return windows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub :  {'a': <_VariantDataset shapes: (), types: tf.int64>, 'b': <_VariantDataset shapes: (), types: tf.int64>}\n",
      "type(sub) :  <class 'dict'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/760946245.py\", line 10, in sub_to_batch  *\n        return sub.batch(window_size, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[180], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmake_window_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzipped\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[176], line 12\u001B[0m, in \u001B[0;36mmake_window_dataset\u001B[0;34m(ds, window_size, shift, stride)\u001B[0m\n\u001B[1;32m      8\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype(sub) : \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mtype\u001B[39m(sub))\n\u001B[1;32m     10\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m sub\u001B[38;5;241m.\u001B[39mbatch(window_size, drop_remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 12\u001B[0m windows \u001B[38;5;241m=\u001B[39m \u001B[43mwindows\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_to_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m windows\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2048\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[0;34m(self, map_func, name)\u001B[0m\n\u001B[1;32m   2014\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_map\u001B[39m(\u001B[38;5;28mself\u001B[39m, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2015\u001B[0m   \u001B[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \n\u001B[1;32m   2017\u001B[0m \u001B[38;5;124;03m  The type signature is:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[1;32m   2047\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2048\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5549\u001B[0m, in \u001B[0;36mFlatMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[1;32m   5547\u001B[0m \u001B[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001B[39;00m\n\u001B[1;32m   5548\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[0;32m-> 5549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, DatasetSpec):\n\u001B[1;32m   5552\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   5553\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5554\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_get_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4533\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m   4526\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   4527\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4528\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4529\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4530\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4531\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m-> 4533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4534\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m   4535\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3244\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3236\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[1;32m   3237\u001B[0m \n\u001B[1;32m   3238\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3242\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[1;32m   3243\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3244\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3245\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3246\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   3247\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3210\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3208\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m-> 3210\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3211\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m   3212\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[1;32m   3213\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3557\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3553\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[1;32m   3554\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[1;32m   3556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[0;32m-> 3557\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[1;32m   3560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3392\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3387\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[1;32m   3389\u001B[0m ]\n\u001B[1;32m   3390\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[1;32m   3391\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[0;32m-> 3392\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3393\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3394\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3395\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3397\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3400\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3401\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   3403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[1;32m   3404\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[1;32m   3405\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[1;32m   3406\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[1;32m   3407\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[1;32m   3408\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[1;32m   3409\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   3410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1143\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1141\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1143\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1147\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(convert, func_outputs,\n\u001B[1;32m   1148\u001B[0m                                   expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4510\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4504\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[1;32m   4505\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[1;32m   4506\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[1;32m   4507\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   4508\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[1;32m   4509\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m-> 4510\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4511\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[1;32m   4512\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4440\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4438\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[1;32m   4439\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[0;32m-> 4440\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n\u001B[1;32m   4442\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ret)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:699\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    698\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 699\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m    700\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/760946245.py\", line 10, in sub_to_batch  *\n        return sub.batch(window_size, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n"
     ]
    }
   ],
   "source": [
    "make_window_dataset(zipped)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`tf.data.Dataset.as_numpy_iterator()` is not supported for datasets that produce values of type <class 'tensorflow.python.data.ops.dataset_ops.DatasetV2'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[174], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mlist\u001B[39m(\u001B[43mzipped\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_numpy_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:617\u001B[0m, in \u001B[0;36mDatasetV2.as_numpy_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m component_spec \u001B[38;5;129;01min\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39melement_spec):\n\u001B[1;32m    614\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    615\u001B[0m       component_spec,\n\u001B[1;32m    616\u001B[0m       (tensor_spec\u001B[38;5;241m.\u001B[39mTensorSpec, ragged_tensor\u001B[38;5;241m.\u001B[39mRaggedTensorSpec)):\n\u001B[0;32m--> 617\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    618\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset.as_numpy_iterator()` is not supported for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    619\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets that produce values of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomponent_spec\u001B[38;5;241m.\u001B[39mvalue_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _NumpyIterator(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: `tf.data.Dataset.as_numpy_iterator()` is not supported for datasets that produce values of type <class 'tensorflow.python.data.ops.dataset_ops.DatasetV2'>"
     ]
    }
   ],
   "source": [
    "list(zipped.window(3, shift=1, stride=1).as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "[(array([1, 2, 3, 4]), array([16, 17, 18, 19]))]"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched = zipped.batch(4, drop_remainder=True).take(1)\n",
    "list(batched.as_numpy_iterator())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [array([1, 2, 3, 4, 5, 6], dtype=int32)], 'l': [array([b'a', b'b', b'c', b'd', b'e', b'f'], dtype=object)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 22:56:41.531924: W tensorflow/core/framework/dataset.cc:744] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "windows = ds.window(3, shift=1, stride=1)\n",
    "def to_numpy(ds):\n",
    "  return list(ds.as_numpy_iterator())\n",
    "\n",
    "for w in windows:\n",
    "  print(tf.nest.map_structure(to_numpy, w))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': TensorSpec(shape=(), dtype=tf.int32, name=None),\n 'l': TensorSpec(shape=(), dtype=tf.string, name=None)}"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices({\n",
    "    'x': [1, 2, 3, 4, 5, 6, 7, 8 , 9 ],\n",
    "    'l': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i' ]\n",
    "})\n",
    "# }).batch(6).take(1)\n",
    "\n",
    "ds.element_spec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'x': 1, 'l': b'a'},\n {'x': 2, 'l': b'b'},\n {'x': 3, 'l': b'c'},\n {'x': 4, 'l': b'd'},\n {'x': 5, 'l': b'e'},\n {'x': 6, 'l': b'f'},\n {'x': 7, 'l': b'g'},\n {'x': 8, 'l': b'h'},\n {'x': 9, 'l': b'i'}]"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(ds)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [1, 2, 3], 'l': [b'a', b'b', b'c']}\n",
      "{'x': [2, 3, 4], 'l': [b'b', b'c', b'd']}\n",
      "{'x': [3, 4, 5], 'l': [b'c', b'd', b'e']}\n",
      "{'x': [4, 5, 6], 'l': [b'd', b'e', b'f']}\n",
      "{'x': [5, 6, 7], 'l': [b'e', b'f', b'g']}\n",
      "{'x': [6, 7, 8], 'l': [b'f', b'g', b'h']}\n",
      "{'x': [7, 8, 9], 'l': [b'g', b'h', b'i']}\n",
      "{'x': [8, 9], 'l': [b'h', b'i']}\n",
      "{'x': [9], 'l': [b'i']}\n"
     ]
    }
   ],
   "source": [
    "windows = ds.window(3, shift=1, stride=1)\n",
    "for w in windows:\n",
    "    # print(w.to_numpy())\n",
    "  print(tf.nest.map_structure(to_numpy, w))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x14a1be910>, 'l': <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x14a1bee80>}\n",
      "{'x': <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x14a1be820>, 'l': <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x14a1be580>}\n"
     ]
    }
   ],
   "source": [
    "for w in windows.batch(6):\n",
    "  print(w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n TensorSpec(shape=(None,), dtype=tf.string, name=None))"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(\n",
    "    ([1, 2, 3, 4, 5, 6, 7, 8 , 9 ],['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i' ])\n",
    "# )\n",
    ").batch(6).take(1)\n",
    "\n",
    "ds.element_spec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "[(array([1, 2, 3, 4, 5, 6], dtype=int32),\n  array([b'a', b'b', b'c', b'd', b'e', b'f'], dtype=object))]"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([1, 2, 3, 4, 5, 6], dtype=int32)], [array([b'a', b'b', b'c', b'd', b'e', b'f'], dtype=object)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 23:32:37.084974: W tensorflow/core/framework/dataset.cc:744] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "windows = ds.window(3, shift=1, stride=1)\n",
    "for w in windows:\n",
    "  print(tf.nest.map_structure(to_numpy, w))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 21:54:28.941879: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-11 21:54:29.137967: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n"
     ]
    }
   ],
   "source": [
    "dataset = tfio.experimental.IODataset.from_sql(\n",
    "    query=query_tmp.format('BTC/USDT', 200),\n",
    "    endpoint=endpoint,\n",
    "# )\n",
    ").batch(50).shuffle(9).take(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "{'time': TensorSpec(shape=(None,), dtype=tf.float64, name=None),\n 'open': TensorSpec(shape=(None,), dtype=tf.float64, name=None)}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.element_spec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([1.66500834e+09, 1.66500828e+09, 1.66500822e+09, 1.66500816e+09,\n",
      "       1.66500810e+09, 1.66500804e+09, 1.66500798e+09, 1.66500792e+09,\n",
      "       1.66500786e+09, 1.66500780e+09, 1.66500774e+09, 1.66500768e+09,\n",
      "       1.66500762e+09, 1.66500756e+09, 1.66500750e+09, 1.66500744e+09,\n",
      "       1.66500738e+09, 1.66500732e+09, 1.66500726e+09, 1.66500720e+09,\n",
      "       1.66500714e+09, 1.66500708e+09, 1.66500702e+09, 1.66500696e+09,\n",
      "       1.66500690e+09, 1.66500684e+09, 1.66500678e+09, 1.66500672e+09,\n",
      "       1.66500666e+09, 1.66500660e+09, 1.66500654e+09, 1.66500648e+09,\n",
      "       1.66500642e+09, 1.66500636e+09, 1.66500630e+09, 1.66500624e+09,\n",
      "       1.66500618e+09, 1.66500612e+09, 1.66500606e+09, 1.66500600e+09,\n",
      "       1.66500594e+09, 1.66500588e+09, 1.66500582e+09, 1.66500576e+09,\n",
      "       1.66500570e+09, 1.66500564e+09, 1.66500558e+09, 1.66500552e+09,\n",
      "       1.66500546e+09, 1.66500540e+09])>, 'open': <tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
      "array([20131.78, 20068.43, 20068.39, 20049.05, 20038.41, 20029.76,\n",
      "       20037.33, 20021.42, 20027.29, 20027.65, 20023.41, 20027.77,\n",
      "       20032.53, 20044.22, 20053.39, 20039.95, 20057.04, 20057.47,\n",
      "       20061.1 , 20050.44, 20065.43, 20057.46, 20062.05, 20067.08,\n",
      "       20042.17, 20037.63, 20032.03, 20048.84, 20033.2 , 20016.63,\n",
      "       20043.57, 20074.  , 20076.97, 20073.26, 20069.36, 20072.66,\n",
      "       20052.42, 20059.64, 20052.27, 20042.61, 20043.72, 20061.86,\n",
      "       20068.44, 20092.3 , 20073.21, 20048.86, 20033.09, 20026.7 ,\n",
      "       20030.89, 20029.24])>}\n"
     ]
    }
   ],
   "source": [
    "for element in dataset:\n",
    "  print(element)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'time': array([1.66500534e+09, 1.66500528e+09, 1.66500522e+09, 1.66500516e+09,\n         1.66500510e+09, 1.66500504e+09, 1.66500498e+09, 1.66500492e+09,\n         1.66500486e+09, 1.66500480e+09, 1.66500474e+09, 1.66500468e+09,\n         1.66500462e+09, 1.66500456e+09, 1.66500450e+09, 1.66500444e+09,\n         1.66500438e+09, 1.66500432e+09, 1.66500426e+09, 1.66500420e+09,\n         1.66500414e+09, 1.66500408e+09, 1.66500402e+09, 1.66500396e+09,\n         1.66500390e+09, 1.66500384e+09, 1.66500378e+09, 1.66500372e+09,\n         1.66500366e+09, 1.66500360e+09, 1.66500354e+09, 1.66500348e+09,\n         1.66500342e+09, 1.66500336e+09, 1.66500330e+09, 1.66500324e+09,\n         1.66500318e+09, 1.66500312e+09, 1.66500306e+09, 1.66500300e+09,\n         1.66500294e+09, 1.66500288e+09, 1.66500282e+09, 1.66500276e+09,\n         1.66500270e+09, 1.66500264e+09, 1.66500258e+09, 1.66500252e+09,\n         1.66500246e+09, 1.66500240e+09]),\n  'open': array([20032.54, 20025.39, 20022.71, 20025.03, 20035.74, 20029.6 ,\n         20031.23, 20035.95, 20036.38, 20012.58, 20023.12, 20018.11,\n         20019.8 , 20005.07, 20010.37, 20020.83, 20028.6 , 20039.62,\n         20032.42, 20038.21, 20032.9 , 20040.55, 20010.  , 20022.65,\n         20006.76, 20016.88, 20018.27, 20025.07, 20000.87, 19982.69,\n         20020.96, 20025.97, 20028.62, 20035.22, 20033.46, 20042.99,\n         20041.  , 20054.17, 20052.  , 20039.62, 20070.05, 20083.29,\n         20090.6 , 20088.88, 20099.95, 20100.43, 20100.55, 20099.09,\n         20091.37, 20104.81])}]"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def to_numpy(ds):\n",
    "    l = list(ds.as_numpy_iterator())\n",
    "    return l[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "windows = dataset.window(5, shift=1, stride=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': <_VariantDataset shapes: (None,), types: tf.float64>, 'open': <_VariantDataset shapes: (None,), types: tf.float64>}\n"
     ]
    }
   ],
   "source": [
    "for w in windows:\n",
    "    print(w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'time': array([1.66501434e+09, 1.66501428e+09, 1.66501422e+09, 1.66501416e+09,\n",
      "       1.66501410e+09, 1.66501404e+09, 1.66501398e+09, 1.66501392e+09,\n",
      "       1.66501386e+09, 1.66501380e+09, 1.66501374e+09, 1.66501368e+09,\n",
      "       1.66501362e+09, 1.66501356e+09, 1.66501350e+09, 1.66501344e+09,\n",
      "       1.66501338e+09, 1.66501332e+09, 1.66501326e+09, 1.66501320e+09,\n",
      "       1.66501314e+09, 1.66501308e+09, 1.66501302e+09, 1.66501296e+09,\n",
      "       1.66501290e+09, 1.66501284e+09, 1.66501278e+09, 1.66501272e+09,\n",
      "       1.66501266e+09, 1.66501260e+09, 1.66501254e+09, 1.66501248e+09,\n",
      "       1.66501242e+09, 1.66501236e+09, 1.66501230e+09, 1.66501224e+09,\n",
      "       1.66501218e+09, 1.66501212e+09, 1.66501206e+09, 1.66501200e+09,\n",
      "       1.66501194e+09, 1.66501188e+09, 1.66501182e+09, 1.66501176e+09,\n",
      "       1.66501170e+09, 1.66501164e+09, 1.66501158e+09, 1.66501152e+09,\n",
      "       1.66501146e+09, 1.66501140e+09]), 'open': array([20162.84, 20154.52, 20163.13, 20166.62, 20167.15, 20168.17,\n",
      "       20176.92, 20162.66, 20154.71, 20152.69, 20152.64, 20165.24,\n",
      "       20156.52, 20154.48, 20147.91, 20146.76, 20142.43, 20141.5 ,\n",
      "       20138.57, 20145.88, 20139.23, 20126.22, 20125.8 , 20127.84,\n",
      "       20130.92, 20125.87, 20127.14, 20122.71, 20132.49, 20144.13,\n",
      "       20142.37, 20137.1 , 20144.31, 20149.81, 20163.63, 20163.32,\n",
      "       20171.62, 20165.68, 20164.17, 20152.73, 20148.97, 20163.75,\n",
      "       20177.56, 20163.41, 20155.54, 20156.62, 20152.35, 20146.71,\n",
      "       20146.72, 20133.67])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 22:46:37.205176: W tensorflow/core/framework/dataset.cc:744] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for window in windows:\n",
    "  c+=1\n",
    "  print(c)\n",
    "  print(tf.nest.map_structure(to_numpy, window))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def sub_to_batch(sub):\n",
    "  return sub.batch(5, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/4091595652.py\", line 2, in sub_to_batch  *\n        return sub.batch(5, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m \u001B[43mwindows\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_to_batch\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m      2\u001B[0m   \u001B[38;5;28mprint\u001B[39m(example\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2048\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[0;34m(self, map_func, name)\u001B[0m\n\u001B[1;32m   2014\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_map\u001B[39m(\u001B[38;5;28mself\u001B[39m, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2015\u001B[0m   \u001B[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \n\u001B[1;32m   2017\u001B[0m \u001B[38;5;124;03m  The type signature is:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[1;32m   2047\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2048\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5549\u001B[0m, in \u001B[0;36mFlatMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[1;32m   5547\u001B[0m \u001B[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001B[39;00m\n\u001B[1;32m   5548\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[0;32m-> 5549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, DatasetSpec):\n\u001B[1;32m   5552\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   5553\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5554\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_get_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4533\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m   4526\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   4527\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4528\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4529\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4530\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4531\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m-> 4533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4534\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m   4535\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3244\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3236\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[1;32m   3237\u001B[0m \n\u001B[1;32m   3238\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3242\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[1;32m   3243\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3244\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3245\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3246\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   3247\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3210\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3208\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m-> 3210\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3211\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m   3212\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[1;32m   3213\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3557\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3553\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[1;32m   3554\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[1;32m   3556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[0;32m-> 3557\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[1;32m   3560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3392\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3387\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[1;32m   3389\u001B[0m ]\n\u001B[1;32m   3390\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[1;32m   3391\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[0;32m-> 3392\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3393\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3394\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3395\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3397\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3400\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3401\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   3403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[1;32m   3404\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[1;32m   3405\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[1;32m   3406\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[1;32m   3407\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[1;32m   3408\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[1;32m   3409\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   3410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1143\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1141\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1143\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1147\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(convert, func_outputs,\n\u001B[1;32m   1148\u001B[0m                                   expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4510\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4504\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[1;32m   4505\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[1;32m   4506\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[1;32m   4507\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   4508\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[1;32m   4509\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m-> 4510\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4511\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[1;32m   4512\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4440\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4438\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[1;32m   4439\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[0;32m-> 4440\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n\u001B[1;32m   4442\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ret)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:699\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    698\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 699\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m    700\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/4091595652.py\", line 2, in sub_to_batch  *\n        return sub.batch(5, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n"
     ]
    }
   ],
   "source": [
    "for example in windows.flat_map(sub_to_batch).take(5):\n",
    "  print(example.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The `map_func` argument must return a `Dataset` object. Got <class 'dict'>.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m \u001B[43mwindows\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m      2\u001B[0m   \u001B[38;5;28mprint\u001B[39m(example\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2048\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[0;34m(self, map_func, name)\u001B[0m\n\u001B[1;32m   2014\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_map\u001B[39m(\u001B[38;5;28mself\u001B[39m, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2015\u001B[0m   \u001B[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \n\u001B[1;32m   2017\u001B[0m \u001B[38;5;124;03m  The type signature is:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[1;32m   2047\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2048\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5552\u001B[0m, in \u001B[0;36mFlatMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[1;32m   5549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m StructuredFunctionWrapper(\n\u001B[1;32m   5550\u001B[0m     map_func, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformation_name(), dataset\u001B[38;5;241m=\u001B[39minput_dataset)\n\u001B[1;32m   5551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, DatasetSpec):\n\u001B[0;32m-> 5552\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   5553\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5554\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_get_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5555\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_structure \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure\u001B[38;5;241m.\u001B[39m_element_spec  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   5556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata \u001B[38;5;241m=\u001B[39m dataset_metadata_pb2\u001B[38;5;241m.\u001B[39mMetadata()\n",
      "\u001B[0;31mTypeError\u001B[0m: The `map_func` argument must return a `Dataset` object. Got <class 'dict'>."
     ]
    }
   ],
   "source": [
    "for example in windows.flat_map(lambda x : x).take(5):\n",
    "  print(example.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "  def sub_to_batch(sub):\n",
    "\n",
    "    print('sub : ', sub)\n",
    "    print('type(sub) : ', type(sub))\n",
    "\n",
    "    return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "\n",
    "  return windows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub :  {'time': <_VariantDataset shapes: (), types: tf.float64>, 'open': <_VariantDataset shapes: (), types: tf.float64>}\n",
      "type(sub) :  <class 'dict'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/760946245.py\", line 10, in sub_to_batch  *\n        return sub.batch(window_size, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m windowed_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mmake_window_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[50], line 12\u001B[0m, in \u001B[0;36mmake_window_dataset\u001B[0;34m(ds, window_size, shift, stride)\u001B[0m\n\u001B[1;32m      8\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype(sub) : \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mtype\u001B[39m(sub))\n\u001B[1;32m     10\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m sub\u001B[38;5;241m.\u001B[39mbatch(window_size, drop_remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 12\u001B[0m windows \u001B[38;5;241m=\u001B[39m \u001B[43mwindows\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43msub_to_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m windows\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2048\u001B[0m, in \u001B[0;36mDatasetV2.flat_map\u001B[0;34m(self, map_func, name)\u001B[0m\n\u001B[1;32m   2014\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_map\u001B[39m(\u001B[38;5;28mself\u001B[39m, map_func, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2015\u001B[0m   \u001B[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \n\u001B[1;32m   2017\u001B[0m \u001B[38;5;124;03m  The type signature is:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2046\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[1;32m   2047\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2048\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFlatMapDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5549\u001B[0m, in \u001B[0;36mFlatMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, name)\u001B[0m\n\u001B[1;32m   5547\u001B[0m \u001B[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001B[39;00m\n\u001B[1;32m   5548\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[0;32m-> 5549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure, DatasetSpec):\n\u001B[1;32m   5552\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   5553\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   5554\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_get_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func\u001B[38;5;241m.\u001B[39moutput_structure)\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4533\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m   4526\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   4527\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4528\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4529\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   4530\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4531\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m-> 4533\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4534\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m   4535\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3244\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3236\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001B[39;00m\n\u001B[1;32m   3237\u001B[0m \n\u001B[1;32m   3238\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3242\u001B[0m \u001B[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001B[39;00m\n\u001B[1;32m   3243\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3244\u001B[0m   graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3245\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3246\u001B[0m   graph_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   3247\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3210\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3208\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   3209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m-> 3210\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3211\u001B[0m   seen_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m   3212\u001B[0m   captured \u001B[38;5;241m=\u001B[39m object_identity\u001B[38;5;241m.\u001B[39mObjectIdentitySet(\n\u001B[1;32m   3213\u001B[0m       graph_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minternal_captures)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3557\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3553\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[1;32m   3554\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[1;32m   3556\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[0;32m-> 3557\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3558\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[1;32m   3560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3392\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3387\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[1;32m   3389\u001B[0m ]\n\u001B[1;32m   3390\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[1;32m   3391\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[0;32m-> 3392\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3393\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3394\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3395\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3397\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3400\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3401\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   3403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[1;32m   3404\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[1;32m   3405\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[1;32m   3406\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[1;32m   3407\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[1;32m   3408\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[1;32m   3409\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   3410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1143\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1141\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1143\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1147\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(convert, func_outputs,\n\u001B[1;32m   1148\u001B[0m                                   expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4510\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4504\u001B[0m \u001B[38;5;129m@eager_function\u001B[39m\u001B[38;5;241m.\u001B[39mdefun_with_attributes(\n\u001B[1;32m   4505\u001B[0m     input_signature\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_specs(\n\u001B[1;32m   4506\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_structure),\n\u001B[1;32m   4507\u001B[0m     autograph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   4508\u001B[0m     attributes\u001B[38;5;241m=\u001B[39mdefun_kwargs)\n\u001B[1;32m   4509\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m-> 4510\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4511\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[1;32m   4512\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4440\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   4438\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[1;32m   4439\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[0;32m-> 4440\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n\u001B[1;32m   4442\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ret)\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:699\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    698\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 699\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[1;32m    700\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: in user code:\n\n    File \"/var/folders/nb/493_knds4wb1xy3lp5v1c8b40000gn/T/ipykernel_81092/760946245.py\", line 10, in sub_to_batch  *\n        return sub.batch(window_size, drop_remainder=True)\n\n    AttributeError: 'dict' object has no attribute 'batch'\n"
     ]
    }
   ],
   "source": [
    "windowed_dataset = make_window_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<TakeDataset shapes: {time: DatasetSpec(TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorShape([])), open: DatasetSpec(TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorShape([]))}, types: {time: DatasetSpec(TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorShape([])), open: DatasetSpec(TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorShape([]))}>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.take(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'time': array([1.66501434e+09, 1.66501428e+09, 1.66501422e+09, ...,\n        1.66489452e+09, 1.66489446e+09, 1.66489440e+09]),\n 'open': array([20162.84, 20154.52, 20163.13, ..., 20107.29, 20095.2 , 20075.02])}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset.take(1).as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 23:44:25.181513: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-10 23:44:25.327798: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n",
      "2022-12-10 23:44:25.562968: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-10 23:44:25.777863: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n"
     ]
    }
   ],
   "source": [
    "dataset_btc = tfio.experimental.IODataset.from_sql(\n",
    "    query=\"SELECT extract(epoch from time) AS time, open FROM ohlc_candleseries WHERE symbol = 'BTC/USDT' LIMIT 2000;\",\n",
    "    endpoint=endpoint,\n",
    ")\n",
    "dataset_ltc = tfio.experimental.IODataset.from_sql(\n",
    "    query=\"SELECT extract(epoch from time) AS time, open FROM ohlc_candleseries WHERE symbol = 'LTC/USDT' LIMIT 2000;\",\n",
    "    endpoint=endpoint,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ({time: (), open: ()}, {time: (), open: ()}), types: ({time: tf.float64, open: tf.float64}, {time: tf.float64, open: tf.float64})>\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.zip((dataset_btc, dataset_ltc))\n",
    "print(ds.take(1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def construct_dataset(symbols=('BTC/USDT', 'ETH/USDT', 'LTC/USDT'), limit=1000):\n",
    "    \"\"\"\n",
    "    helper to construct tf dataset.\n",
    "    since we can only read 2D data from SQL, we need to zip multiple datasets to build 3D tensor\n",
    "    \"\"\"\n",
    "    ENDPOINT =\"postgresql://{}:{}@{}?port={}&dbname={}\".format(\n",
    "        os.environ['DATABASE_USER'],\n",
    "        os.environ['DATABASE_PASSWORD'],\n",
    "        os.environ['DATABASE_HOST'],\n",
    "        os.environ['DATABASE_PORT'],\n",
    "        os.environ['DATABASE_NAME'],\n",
    "    )\n",
    "\n",
    "    QUERY = \"SELECT extract(epoch from time) AS time, open FROM ohlc_candleseries WHERE symbol = '{}' LIMIT {};\"\n",
    "\n",
    "    datasets = []\n",
    "\n",
    "    for symbol in symbols:\n",
    "        datasets.append(\n",
    "            tfio.experimental.IODataset.from_sql(\n",
    "                query=QUERY.format(symbol, limit),\n",
    "                endpoint=ENDPOINT,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print('created datasets')\n",
    "\n",
    "    dataset =  tf.data.Dataset.zip(tuple(datasets))\n",
    "\n",
    "    return dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 23:58:08.705088: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-10 23:58:09.243605: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n",
      "2022-12-10 23:58:09.373026: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n",
      "2022-12-10 23:58:10.079177: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n",
      "2022-12-10 23:58:10.147173: I tensorflow_io/core/kernels/sql_kernels.cc:89] Connection to database succeed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 23:58:11.072170: I tensorflow_io/core/kernels/sql_kernels.cc:96] Exec of query succeed.\n"
     ]
    }
   ],
   "source": [
    "dataset = construct_dataset(symbols=('BTC/USDT', 'ETH/USDT', 'LTC/USDT'), limit=60000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "current_batch = dataset.batch(3000).shuffle(9).take(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "windows = current_batch.window(30, shift=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[210], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m window \u001B[38;5;129;01min\u001B[39;00m windows:\n\u001B[1;32m      2\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m window:\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mval\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m(), end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "for window in windows:\n",
    "  for val in window:\n",
    "    print(val.numpy(), end=\" \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class DataGenerator(object):\n",
    "    \"\"\"Acts as data provider for each new episode.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, symbols, steps=30, window_size=14, batch_size=3000):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            dataset: (num_stocks, timestamp, 5) open, high, low, close, volume\n",
    "            symbols: a list of length num_stocks with assets name\n",
    "            steps: the total number of steps to simulate, default is 2 years\n",
    "            window_size: observation window, must be less than 50\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps + 1\n",
    "        self.n_episodes = int(self.batch_size / self.steps)\n",
    "        self.step = 0\n",
    "        self.window_size = window_size\n",
    "        # make immutable class\n",
    "        self._dataset = dataset\n",
    "        self.current_batch = None\n",
    "        self.windows_obs = None\n",
    "        self.window_gt = None\n",
    "\n",
    "        self.symbols = symbols\n",
    "        self.cur_obs = None\n",
    "        self.cur_gt = None\n",
    "\n",
    "    def _step(self):\n",
    "        self.step += 1\n",
    "        self.cur_obs = next(self.windows_obs)\n",
    "        self.cur_gt = next(self.windows_gt)\n",
    "\n",
    "        done = self.step >= self.steps\n",
    "        return self.cur_obs, done, self.cur_gt\n",
    "\n",
    "    def reset(self):\n",
    "        self.step = 0\n",
    "        self.current_batch = self._dataset.batch(self.batch_size).shuffle(9).take(1)\n",
    "        self.windows_obs = self.current_batch.window(self.window_size, shift=1)\n",
    "        self.windows_gt = self.current_batch.window(self.window_size, shift=1)\n",
    "        # increment for (future) gt observation\n",
    "        # next(self.windows_gt)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "dg = DataGenerator(dataset, symbols=('BTC/USDT', 'ETH/USDT', 'LTC/USDT'), steps=30, window_size=14, batch_size=3000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "dg.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "['_GeneratorState',\n '__abstractmethods__',\n '__bool__',\n '__class__',\n '__class_getitem__',\n '__debug_string__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__nonzero__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__slotnames__',\n '__slots__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_abc_impl',\n '_add_trackable_child',\n '_add_variable_with_custom_getter',\n '_apply_debug_options',\n '_as_serialized_graph',\n '_checkpoint_dependencies',\n '_consumers',\n '_deferred_dependencies',\n '_deserialize_from_proto',\n '_drop_remainder',\n '_flat_shapes',\n '_flat_structure',\n '_flat_types',\n '_functions',\n '_gather_saveables_for_checkpoint',\n '_graph',\n '_graph_attr',\n '_handle_deferred_dependencies',\n '_input_dataset',\n '_inputs',\n '_list_extra_dependencies_for_serialization',\n '_list_functions_for_serialization',\n '_lookup_dependency',\n '_map_resources',\n '_maybe_initialize_trackable',\n '_maybe_track_assets',\n '_metadata',\n '_name_based_attribute_restore',\n '_name_based_restores',\n '_no_dependency',\n '_object_identifier',\n '_options',\n '_options_attr',\n '_options_tensor_to_options',\n '_preload_simple_restoration',\n '_restore_from_checkpoint_position',\n '_self_name_based_restores',\n '_self_saveable_object_factories',\n '_self_setattr_tracking',\n '_self_unconditional_checkpoint_dependencies',\n '_self_unconditional_deferred_dependencies',\n '_self_unconditional_dependency_names',\n '_self_update_uid',\n '_serialize_to_proto',\n '_setattr_tracking',\n '_shape_invariant_to_type_spec',\n '_shift',\n '_single_restoration_from_checkpoint_position',\n '_size',\n '_stride',\n '_structure',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_trace_variant_creation',\n '_track_trackable',\n '_type_spec',\n '_unconditional_checkpoint_dependencies',\n '_unconditional_dependency_names',\n '_update_uid',\n '_variant_tensor',\n '_variant_tensor_attr',\n '_variant_tracker',\n 'apply',\n 'as_numpy_iterator',\n 'batch',\n 'bucket_by_sequence_length',\n 'cache',\n 'cardinality',\n 'choose_from_datasets',\n 'concatenate',\n 'element_spec',\n 'enumerate',\n 'filter',\n 'flat_map',\n 'from_generator',\n 'from_tensor_slices',\n 'from_tensors',\n 'get_single_element',\n 'group_by_window',\n 'interleave',\n 'list_files',\n 'map',\n 'options',\n 'padded_batch',\n 'prefetch',\n 'random',\n 'range',\n 'reduce',\n 'rejection_resample',\n 'repeat',\n 'sample_from_datasets',\n 'scan',\n 'shard',\n 'shuffle',\n 'skip',\n 'snapshot',\n 'take',\n 'take_while',\n 'unbatch',\n 'unique',\n 'window',\n 'with_options',\n 'zip']"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dg.windows_obs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "['_GeneratorState',\n '__abstractmethods__',\n '__bool__',\n '__class__',\n '__class_getitem__',\n '__debug_string__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__nonzero__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__slots__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_abc_impl',\n '_add_trackable_child',\n '_add_variable_with_custom_getter',\n '_apply_debug_options',\n '_as_serialized_graph',\n '_checkpoint_dependencies',\n '_consumers',\n '_count',\n '_deferred_dependencies',\n '_deserialize_from_proto',\n '_flat_shapes',\n '_flat_structure',\n '_flat_types',\n '_functions',\n '_gather_saveables_for_checkpoint',\n '_graph',\n '_graph_attr',\n '_handle_deferred_dependencies',\n '_input_dataset',\n '_inputs',\n '_list_extra_dependencies_for_serialization',\n '_list_functions_for_serialization',\n '_lookup_dependency',\n '_map_resources',\n '_maybe_initialize_trackable',\n '_maybe_track_assets',\n '_metadata',\n '_name_based_attribute_restore',\n '_name_based_restores',\n '_no_dependency',\n '_object_identifier',\n '_options',\n '_options_attr',\n '_options_tensor_to_options',\n '_preload_simple_restoration',\n '_restore_from_checkpoint_position',\n '_self_name_based_restores',\n '_self_saveable_object_factories',\n '_self_setattr_tracking',\n '_self_unconditional_checkpoint_dependencies',\n '_self_unconditional_deferred_dependencies',\n '_self_unconditional_dependency_names',\n '_self_update_uid',\n '_serialize_to_proto',\n '_setattr_tracking',\n '_shape_invariant_to_type_spec',\n '_single_restoration_from_checkpoint_position',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_trace_variant_creation',\n '_track_trackable',\n '_type_spec',\n '_unconditional_checkpoint_dependencies',\n '_unconditional_dependency_names',\n '_update_uid',\n '_variant_tensor',\n '_variant_tensor_attr',\n '_variant_tracker',\n 'apply',\n 'as_numpy_iterator',\n 'batch',\n 'bucket_by_sequence_length',\n 'cache',\n 'cardinality',\n 'choose_from_datasets',\n 'concatenate',\n 'element_spec',\n 'enumerate',\n 'filter',\n 'flat_map',\n 'from_generator',\n 'from_tensor_slices',\n 'from_tensors',\n 'get_single_element',\n 'group_by_window',\n 'interleave',\n 'list_files',\n 'map',\n 'options',\n 'padded_batch',\n 'prefetch',\n 'random',\n 'range',\n 'reduce',\n 'rejection_resample',\n 'repeat',\n 'sample_from_datasets',\n 'scan',\n 'shard',\n 'shuffle',\n 'skip',\n 'snapshot',\n 'take',\n 'take_while',\n 'unbatch',\n 'unique',\n 'window',\n 'with_options',\n 'zip']"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dg.windows_obs.take(1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TakeDataset' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[170], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindows_obs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'TakeDataset' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "dg.windows_obs.take(1).values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "obs, done, gt = dg._step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfRangeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:800\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 800\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:783\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    782\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[0;32m--> 783\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    784\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    785\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    788\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    789\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:2845\u001B[0m, in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   2844\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 2845\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2846\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7107\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7106\u001B[0m e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7107\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mOutOfRangeError\u001B[0m: End of sequence [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[138], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m obs_2, done_2, gt_2 \u001B[38;5;241m=\u001B[39m \u001B[43mdg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[130], line 34\u001B[0m, in \u001B[0;36mDataGenerator._step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_step\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcur_obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindows_obs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcur_gt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindows_gt)\n\u001B[1;32m     37\u001B[0m     done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps\n",
      "File \u001B[0;32m~/.pyenv/versions/drl-portfolio-management/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:802\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    800\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_internal()\n\u001B[1;32m    801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[0;32m--> 802\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[0;31mStopIteration\u001B[0m: "
     ]
    }
   ],
   "source": [
    "obs_2, done_2, gt_2 = dg._step()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.range(7).window(3, shift=1, drop_remainder=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "iter_1 = iter(ds)\n",
    "iter_2 = iter(ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "['_GeneratorState',\n '__abstractmethods__',\n '__bool__',\n '__class__',\n '__class_getitem__',\n '__debug_string__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__nonzero__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__slots__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_abc_impl',\n '_add_trackable_child',\n '_add_variable_with_custom_getter',\n '_apply_debug_options',\n '_as_serialized_graph',\n '_checkpoint_dependencies',\n '_consumers',\n '_deferred_dependencies',\n '_deserialize_from_proto',\n '_flat_shapes',\n '_flat_structure',\n '_flat_types',\n '_functions',\n '_gather_saveables_for_checkpoint',\n '_graph',\n '_graph_attr',\n '_handle_deferred_dependencies',\n '_inputs',\n '_list_extra_dependencies_for_serialization',\n '_list_functions_for_serialization',\n '_lookup_dependency',\n '_map_resources',\n '_maybe_initialize_trackable',\n '_maybe_track_assets',\n '_name_based_attribute_restore',\n '_name_based_restores',\n '_no_dependency',\n '_object_identifier',\n '_options',\n '_options_attr',\n '_options_tensor_to_options',\n '_preload_simple_restoration',\n '_restore_from_checkpoint_position',\n '_self_name_based_restores',\n '_self_saveable_object_factories',\n '_self_setattr_tracking',\n '_self_unconditional_checkpoint_dependencies',\n '_self_unconditional_deferred_dependencies',\n '_self_unconditional_dependency_names',\n '_self_update_uid',\n '_serialize_to_proto',\n '_setattr_tracking',\n '_shape_invariant_to_type_spec',\n '_single_restoration_from_checkpoint_position',\n '_structure',\n '_tf_api_names',\n '_tf_api_names_v1',\n '_trace_variant_creation',\n '_track_trackable',\n '_type_spec',\n '_unconditional_checkpoint_dependencies',\n '_unconditional_dependency_names',\n '_update_uid',\n '_variant_tensor',\n '_variant_tensor_attr',\n '_variant_tracker',\n 'apply',\n 'as_numpy_iterator',\n 'batch',\n 'bucket_by_sequence_length',\n 'cache',\n 'cardinality',\n 'choose_from_datasets',\n 'concatenate',\n 'element_spec',\n 'enumerate',\n 'filter',\n 'flat_map',\n 'from_generator',\n 'from_tensor_slices',\n 'from_tensors',\n 'get_single_element',\n 'group_by_window',\n 'interleave',\n 'list_files',\n 'map',\n 'options',\n 'padded_batch',\n 'prefetch',\n 'random',\n 'range',\n 'reduce',\n 'rejection_resample',\n 'repeat',\n 'sample_from_datasets',\n 'scan',\n 'shard',\n 'shuffle',\n 'skip',\n 'snapshot',\n 'take',\n 'take_while',\n 'unbatch',\n 'unique',\n 'window',\n 'with_options',\n 'zip']"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2]"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(next(iter_2).as_numpy_iterator())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3]"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(next(iter_1).as_numpy_iterator())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 2, 3]\n",
      "[2, 3, 4]\n",
      "[3, 4, 5]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
    "                                          drop_remainder=True)\n",
    "for window in dataset:\n",
    "  print(list(window.as_numpy_iterator()))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def plot_batch_sizes(ds):\n",
    "  batch_sizes = [batch['time'].shape[0] for batch in ds]\n",
    "  plt.bar(range(len(batch_sizes)), batch_sizes)\n",
    "  plt.xlabel('Batch number')\n",
    "  plt.ylabel('Batch size')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "batches = dataset.batch(128)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_batch_sizes(batches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data and choose the target stocks for training a toy example\n",
    "history, abbreviation = read_stock_history(filepath='utils/datasets/stocks_history_target.h5')\n",
    "history = history[:, :, :4]\n",
    "target_stocks = ['AAPL', 'CMCSA', 'REGN']\n",
    "training_date_start = '2012-08-13'\n",
    "training_date_end = '2015-08-13'  # three years training data\n",
    "training_index_start = date_to_index(training_date_start)\n",
    "training_index_end = date_to_index(training_date_end)\n",
    "target_history = np.empty(shape=(len(target_stocks), training_index_end - training_index_start, history.shape[2]))\n",
    "for i, stock in enumerate(target_stocks):\n",
    "    target_history[i] = history[abbreviation.index(stock), training_index_start:training_index_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1, 16, 4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 1095, 4)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_history.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect testing data\n",
    "testing_date_start = '2015-08-13'\n",
    "testing_date_end = '2017-08-12'\n",
    "testing_index_start = date_to_index(testing_date_start)\n",
    "testing_index_end = date_to_index(testing_date_end)\n",
    "testing_history = np.empty(shape=(len(target_stocks), testing_index_end - testing_index_start, history.shape[2]))\n",
    "for i, stock in enumerate(target_stocks):\n",
    "    testing_history[i] = history[abbreviation.index(stock), testing_index_start:testing_index_end, :]\n",
    "# normalize\n",
    "for i in range(target_history.shape[0]):\n",
    "    for j in range(target_history.shape[1]):\n",
    "        target_history[i][j] = target_history[i][j]/np.linalg.norm(target_history[i][j])\n",
    "for i in range(testing_history.shape[0]):\n",
    "    for j in range(testing_history.shape[1]):\n",
    "        testing_history[i][j] = testing_history[i][j]/np.linalg.norm(testing_history[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1095, 4)\n",
      "(3, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "print(target_history.shape)\n",
    "print(testing_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEkCAYAAAAxaHaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noahQoUKFCnXx/5os6yp56KmkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8aa0114a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEkCAYAAAAvoUY9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a7406ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEkCAYAAADD+OFuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a71fd5e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize 3 stock open price\n",
    "date_list = [index_to_date(i) for i in range(target_history.shape[1])]\n",
    "x = range(target_history.shape[1])\n",
    "for i in range(len(target_stocks)):\n",
    "    plt.figure(i)\n",
    "    plt.plot(x, target_history[i, :, 1])  # open, high, low, close = [0, 1, 2, 3]\n",
    "    plt.xticks(x[::200], date_list[::200], rotation=30)\n",
    "    plt.title(target_stocks[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "0.0025\n"
     ]
    }
   ],
   "source": [
    "from environment.portfolio import PortfolioEnv\n",
    "env = PortfolioEnv(target_history, target_stocks, window_length = 1)\n",
    "print(env.window_length)\n",
    "print(env.num_stocks)\n",
    "print(env.sim.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training and testing data\n",
    "trainX = np.zeros(((target_history.shape[1]-env.window_length)*(env.num_stocks+1), 4, env.window_length+1, env.num_stocks))\n",
    "testX = np.zeros(((testing_history.shape[1]-env.window_length)*(env.num_stocks+1), 4, env.window_length+1, env.num_stocks))\n",
    "trainY = np.zeros(((target_history.shape[1]-env.window_length)*(env.num_stocks+1), env.num_stocks+1))\n",
    "testY = np.zeros(((testing_history.shape[1]-env.window_length)*(env.num_stocks+1), env.num_stocks+1))\n",
    "for i in range(target_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks + 1):\n",
    "        for j in range(4):\n",
    "            for windowIndex in range(env.window_length):\n",
    "                for stock in range(env.num_stocks):\n",
    "                    trainX[i*(env.num_stocks+1)+stockHeld][j][windowIndex][stock] = target_history[stock][i+env.window_length-windowIndex-1][j]\n",
    "            if stockHeld > 0:\n",
    "                trainX[i*(env.num_stocks+1)+stockHeld][j][env.window_length][stockHeld-1] = 1\n",
    "\n",
    "for i in range(testing_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(1, env.num_stocks + 1):\n",
    "        for j in range(4):\n",
    "            for windowIndex in range(env.window_length):\n",
    "                for stock in range(env.num_stocks):\n",
    "                    testX[i*(env.num_stocks+1)+stockHeld][j][windowIndex][stock] = testing_history[stock][i+env.window_length-windowIndex-1][j]\n",
    "            if stockHeld > 0:\n",
    "                testX[i*(env.num_stocks+1)+stockHeld][j][env.window_length][stockHeld-1] = 1\n",
    "for i in range(target_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks+1):\n",
    "        bestRate = 1.0\n",
    "        bestStock = -1\n",
    "        for stock in range(env.num_stocks):\n",
    "            trading_cost = env.sim.cost\n",
    "            if stockHeld-1 == stock:\n",
    "                trading_cost = 0\n",
    "            # print(trainX[i*(env.num_stocks+1) + stockHeld][3][0][stock], target_history[stock][i+env.window_length-1][3])\n",
    "            rate = target_history[stock][i+env.window_length-1][3]/target_history[stock][i+env.window_length-1][0] - trading_cost\n",
    "            if rate > bestRate:\n",
    "                bestRate = rate\n",
    "                bestStock = stock\n",
    "        trainY[i*(env.num_stocks+1) + stockHeld][bestStock+1] = 1\n",
    "for i in range(testing_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks+1):\n",
    "        bestRate = 1.0\n",
    "        bestStock = -1\n",
    "        for stock in range(env.num_stocks):\n",
    "            trading_cost = env.sim.cost\n",
    "            if stockHeld-1 == stock:\n",
    "                trading_cost = 0\n",
    "            rate = testing_history[stock][i+env.window_length-1][3]/testing_history[stock][i+env.window_length-1][0] - trading_cost\n",
    "            if rate > bestRate:\n",
    "                bestRate = rate\n",
    "                bestStock = stock\n",
    "        testY[i*(env.num_stocks+1) + stockHeld][bestStock+1] = 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model from scratch\n"
     ]
    }
   ],
   "source": [
    "from model.supervised.cnn import CNN\n",
    "# instantiate CNN model\n",
    "cnn_model = CNN(env=env)\n",
    "cnn_model.build_model(load_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4376/4376 [==============================] - 4s - loss: 5.8845 - acc: 0.2347     \n",
      "Epoch 2/10\n",
      "4376/4376 [==============================] - 4s - loss: 6.5143 - acc: 0.2514     \n",
      "Epoch 3/10\n",
      "4376/4376 [==============================] - 4s - loss: 5.4075 - acc: 0.2278     \n",
      "Epoch 4/10\n",
      "4376/4376 [==============================] - 4s - loss: 6.1577 - acc: 0.2356     - ETA: \n",
      "Epoch 5/10\n",
      "4376/4376 [==============================] - 4s - loss: 5.3662 - acc: 0.2242     \n",
      "Epoch 6/10\n",
      "4376/4376 [==============================] - 4s - loss: 4.1719 - acc: 0.2246     \n",
      "Epoch 7/10\n",
      "4376/4376 [==============================] - 4s - loss: 3.9642 - acc: 0.2253     \n",
      "Epoch 8/10\n",
      "4376/4376 [==============================] - 4s - loss: 3.9535 - acc: 0.2233     \n",
      "Epoch 9/10\n",
      "4376/4376 [==============================] - 4s - loss: 4.0419 - acc: 0.2230     \n",
      "Epoch 10/10\n",
      "4376/4376 [==============================] - 4s - loss: 3.9527 - acc: 0.2228     \n",
      "Finish.\n"
     ]
    }
   ],
   "source": [
    "# starts to train the model, hopefully it would work\n",
    "cnn_model.train(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  0.  1.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 1.  0.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  1.  0.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.22769251  0.21792054  0.15906529  0.3953217 ] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.] [ 0.  0.  1.  0.]\n",
      "[8.5830439317700638, 0.31652949245541839]\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "predictions = cnn_model.predict(testX)\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i], testY[i])\n",
    "score = cnn_model.evaluate(testX, testY)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddpg_model_from_file = DDPG(env=env)\n",
    "ddpg_model_from_file.build_model(load_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model with training data\n",
    "env = PortfolioEnv(target_history, target_stocks)\n",
    "observation, action = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    observation = observation[:, :, 3] / observation[:, :, 0]\n",
    "#     print(observation)\n",
    "    observation = np.expand_dims(observation, axis=-1)\n",
    "    action = ddpg_model_from_file.predict(observation)\n",
    "    action = np.squeeze(action, axis=0)\n",
    "#     print(action)\n",
    "#     input('Press any key to continue...')\n",
    "    observation, _, done, _ = env.step(action)\n",
    "env._render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model with unseen data from same stock\n",
    "env = PortfolioEnv(testing_history, target_stocks, steps=650, start_idx=testing_index_start, \n",
    "                   sample_start_date='2015-10-02')\n",
    "observation, action = env.reset()\n",
    "done = False\n",
    "for i in range(10):\n",
    "    observation = observation[:, :, 3] / observation[:, :, 0] * 100\n",
    "    observation = np.expand_dims(observation, axis=-1)\n",
    "    action = ddpg_model_from_file.predict(observation)\n",
    "    action = np.squeeze(action, axis=0)\n",
    "#     print(action)\n",
    "    observation, _, done, _ = env.step(action)\n",
    "env._render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('temp/total_reward_state_1.npz', stat=ddpg_model.total_reward_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot episode reward and save it\n",
    "total_reward_stat = np.load('temp/total_reward_state_1.npz')['stat']\n",
    "x = range(len(total_reward_stat))[::20]\n",
    "plt.plot(x, total_reward_stat[::20])\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect testing data of another 3 different companies\n",
    "target_stocks = ['GOOGL', 'CSX', 'MAR']\n",
    "testing_date_start = '2012-08-13'\n",
    "testing_date_end = '2017-08-12'\n",
    "testing_index_start = date_to_index(testing_date_start)\n",
    "testing_index_end = date_to_index(testing_date_end)\n",
    "testing_history = np.empty(shape=(len(target_stocks), testing_index_end - testing_index_start, history.shape[2]))\n",
    "for i, stock in enumerate(target_stocks):\n",
    "    testing_history[i] = history[abbreviation.index(stock), testing_index_start:testing_index_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model with unseen data from different stocks\n",
    "env = PortfolioEnv(testing_history, target_stocks, steps=1700, start_idx=testing_index_start)\n",
    "observation, action = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    observation = observation[:, :, 3] / observation[:, :, 0]\n",
    "    observation = np.expand_dims(observation, axis=-1)\n",
    "    action = ddpg_model.predict(observation)\n",
    "    action = np.squeeze(action, axis=0)\n",
    "    observation, _, done, _ = env.step(action)\n",
    "env._render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddpg_model.actor.model.save_weights(ddpg_model.actor_path)\n",
    "ddpg_model.critic.model.save_weights(ddpg_model.critic_path)\n",
    "ddpg_model.actor.target_model.save_weights(ddpg_model.actor_target_path)\n",
    "ddpg_model.critic.target_model.save_weights(ddpg_model.critic_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_index = 1\n",
    "# check model load\n",
    "ddpg_model.actor.model.get_layer(index=layer_index).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddpg_model_from_file.actor.model.get_layer(index=layer_index).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
